/**
 * Setup Wizard Module
 * Interactive setup wizard for configuring AI providers and integrations
 */

import inquirer from 'inquirer';
import chalk from 'chalk';
import {
  ensureConfigDir,
  getAIConfig,
  getAvailableProviders,
  getProviderDefaultApiKeyEnv,
  setAIConfig,
  getConfigValue,
  setConfigValue
} from '../core/config.js';
import { loadUserEnv, upsertUserEnvVar } from '../core/env.js';

/**
 * Run the setup wizard
 */
export async function setupWizard() {
  await ensureConfigDir();

  console.log(chalk.cyan('\n╔═══════════════════════════════════════════════════════════╗'));
  console.log(chalk.cyan('║') + chalk.white('         ProtoForge Setup Wizard') + chalk.cyan('                       ║'));
  console.log(chalk.cyan('╚═══════════════════════════════════════════════════════════╝\n'));

  try {
    loadUserEnv();

    const providers = getAvailableProviders();
    const current = getAIConfig();

    // 1) Provider (default Ollama)
    const step1 = await inquirer.prompt([
      {
        type: 'list',
        name: 'provider',
        message: 'AI provider (API key required):',
        choices: providers
          .filter((p) => !['ollama', 'custom', 'mock'].includes(p.id))
          .map((p) => ({ name: p.name, value: p.id })),
        default: current.provider && current.provider !== 'ollama' ? current.provider : 'openai'
      }
    ]);

    // 2) API key (cloud) + model (NO Ollama prompts)
    const provider = step1.provider;

    const defaults = {
      openai: { model: 'gpt-4o-mini' },
      groq: { model: 'llama-3.1-70b-versatile' },
      anthropic: { model: 'claude-3-5-sonnet-20241022' },
      gemini: { model: 'gemini-1.5-flash' },
      deepseek: { model: 'deepseek-chat' }
    };

    const providerEnv = getProviderDefaultApiKeyEnv(provider);
    const existingEnvKey = providerEnv ? process.env[providerEnv] : '';

    // If key is already present via env var, prefer that and avoid prompting.
    let apiKey = '';
    let storeMode = 'env';

    if (existingEnvKey) {
      const stepKey = await inquirer.prompt([
        {
          type: 'confirm',
          name: 'useEnv',
          message: `${providerEnv} is already set in your environment. Use it?`,
          default: true
        }
      ]);
      if (stepKey.useEnv) {
        apiKey = '';
        storeMode = 'env';
      }
    }

    if (!existingEnvKey) {
      const stepKey = await inquirer.prompt([
        {
          type: 'list',
          name: 'storeMode',
          message: 'How do you want to store your API key?',
          choices: [
            { name: `Save to ~/.protoforge/.env as ${providerEnv} (recommended)`, value: 'env' },
            { name: 'Save to ~/.protoforge/config.json (less recommended)', value: 'config' }
          ],
          default: 'env'
        },
        {
          type: 'password',
          name: 'apiKey',
          message: `API key for ${provider.toUpperCase()} (will not be printed):`,
          validate: (v) => (v && String(v).trim().length ? true : 'API key is required')
        }
      ]);
      apiKey = stepKey.apiKey;
      storeMode = stepKey.storeMode;

      if (storeMode === 'env') {
        await upsertUserEnvVar(providerEnv, apiKey);
        // Load it into current process for immediate use.
        process.env[providerEnv] = apiKey;
      }
    }

    const step2 = await inquirer.prompt([
      {
        type: 'input',
        name: 'model',
        message: provider === 'gemini'
          ? 'Model name (example: gemini-1.5-flash)'
          : 'Model name:',
        default: () => getConfigValue('model', defaults[provider]?.model || 'gpt-4o-mini'),
        validate: (v) => {
          if (!v || !String(v).trim()) return 'Model is required';
          if (provider === 'gemini') {
            const s = String(v).trim();
            // Accept gemini-*, or models/gemini-* (we normalize in adapter)
            if (!/^((models\/)?gemini-)/i.test(s)) {
              return 'Gemini model should look like gemini-1.5-flash (or models/gemini-1.5-flash)';
            }
          }
          return true;
        }
      }
    ]);

    // 3) Optional 3D preview (HTML) is generated by the model; no Meshy keys.
    console.log(chalk.dim('\nNotes: Mermaid diagrams require no API key. 3D preview is generated as HTML (no Meshy).'));

    // Save provider + model + key config
    // If using env, store nothing sensitive in config.
    setAIConfig({
      provider,
      model: step2.model,
      apiKey: storeMode === 'config' ? apiKey : '',
      apiKeyEnv: ''
    });

    const step3 = await inquirer.prompt([
      {
        type: 'input',
        name: 'outputDir',
        message: 'Output directory for generated projects:',
        default: getConfigValue('outputDir', './protoforge-output')
      },
      {
        type: 'confirm',
        name: 'autoOpenWeb',
        message: 'Auto-open web browser when starting the web UI?',
        default: getConfigValue('autoOpenWeb', false)
      },
      {
        type: 'input',
        name: 'webPort',
        message: 'Web UI port:',
        default: String(getConfigValue('webPort', 3000)),
        filter: (v) => Number(v)
      }
    ]);

    setConfigValue('outputDir', step3.outputDir);
    setConfigValue('autoOpenWeb', step3.autoOpenWeb);
    setConfigValue('webPort', step3.webPort);

    console.log('\n' + chalk.green('✓ Setup complete'));
    console.log(chalk.dim('Next:'));
    console.log(`  • ${chalk.cyan('Run protoforge start')} to open the terminal chat interface`);
    console.log(`  • ${chalk.cyan('Run protoforge web')} to open the web dashboard at ${chalk.cyan(`http://localhost:${step3.webPort}`)}`);
    console.log(chalk.dim('Tip: Use the web version to edit projects, view code, diagrams, 3D preview, BOM, and the build guide.'));
  } catch (error) {
    if (error?.isTtyError) {
      console.log(chalk.yellow('\nInteractive prompts not supported in this environment.'));
      console.log(chalk.dim('You can configure manually via: protoforge config --set key=value'));
      return;
    }
    throw error;
  }
}

export default { setupWizard };
